epoch,train_loss,cal_loss
1,4.0991224343493835,1.3610205173492431
2,1.3841559109041246,1.0137515366077423
3,1.1465894307120372,0.8299847900867462
4,1.0848149596634558,0.78958258330822
5,1.0503860934306,0.7361719608306885
6,1.0206534559443845,0.7009276270866394
7,1.003632613157822,0.6835312008857727
8,0.995091811580173,0.6872037097811698
9,0.9858536275766664,0.6782211601734162
10,0.9763231686616348,0.6629291117191315
11,0.9734714329242706,0.6683108195662498
12,0.9686670313447209,0.6698357880115509
13,0.9651198240660005,0.6701245471835137
14,0.9604087330527225,0.6756817653775216
15,0.9581386239851936,0.6591224566102027
16,0.9561530386997481,0.6733742758631707
17,0.952225456803532,0.6683564960956574
18,0.950779830500231,0.659271103143692
19,0.9492945898387392,0.6599217399954795
20,0.9452001179678965,0.6514236003160476
21,0.9471326263274177,0.6586480259895324
22,0.9456413125587722,0.6596610099077225
23,0.9448606210239863,0.6528962045907974
24,0.9425971826254311,0.6497427761554718
25,0.941413169190035,0.6526841208338737
26,0.9397717673899764,0.6504283756017685
27,0.9364787683648578,0.6530907765030861
28,0.9403840454958253,0.6527824163436889
29,0.9364266461234981,0.6504955381155014
